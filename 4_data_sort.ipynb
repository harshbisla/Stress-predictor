{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of file paths within the sliding_window_data folder\n",
    "file_paths = glob.glob(\"updated_data_sliding/subjectID_*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file: updated_data_sliding\\subjectID_1.csv\n",
      "Updated file: updated_data_sliding\\subjectID_10.csv\n",
      "Updated file: updated_data_sliding\\subjectID_11.csv\n",
      "Updated file: updated_data_sliding\\subjectID_12.csv\n",
      "Updated file: updated_data_sliding\\subjectID_13.csv\n",
      "Updated file: updated_data_sliding\\subjectID_14.csv\n",
      "Updated file: updated_data_sliding\\subjectID_15.csv\n",
      "Updated file: updated_data_sliding\\subjectID_16.csv\n",
      "Updated file: updated_data_sliding\\subjectID_17.csv\n",
      "Updated file: updated_data_sliding\\subjectID_18.csv\n",
      "Updated file: updated_data_sliding\\subjectID_19.csv\n",
      "Updated file: updated_data_sliding\\subjectID_2.csv\n",
      "Updated file: updated_data_sliding\\subjectID_20.csv\n",
      "Updated file: updated_data_sliding\\subjectID_21.csv\n",
      "Updated file: updated_data_sliding\\subjectID_22.csv\n",
      "Updated file: updated_data_sliding\\subjectID_23.csv\n",
      "Updated file: updated_data_sliding\\subjectID_24.csv\n",
      "Updated file: updated_data_sliding\\subjectID_25.csv\n",
      "Updated file: updated_data_sliding\\subjectID_26.csv\n",
      "Updated file: updated_data_sliding\\subjectID_27.csv\n",
      "Updated file: updated_data_sliding\\subjectID_28.csv\n",
      "Updated file: updated_data_sliding\\subjectID_3.csv\n",
      "Updated file: updated_data_sliding\\subjectID_4.csv\n",
      "Updated file: updated_data_sliding\\subjectID_5.csv\n",
      "Updated file: updated_data_sliding\\subjectID_6.csv\n",
      "Updated file: updated_data_sliding\\subjectID_7.csv\n",
      "Updated file: updated_data_sliding\\subjectID_8.csv\n",
      "Updated file: updated_data_sliding\\subjectID_9.csv\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the file paths\n",
    "for file_path in file_paths:\n",
    "    # Load the data from the file\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Rename the first column as \"DateTime\"\n",
    "    data = data.rename(columns={data.columns[0]: \"DateTime\"})\n",
    "    \n",
    "    # Save the updated data back to the file\n",
    "    data.to_csv(file_path, index=False)\n",
    "    \n",
    "    print(\"Updated file:\", file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the dated_data folder\n",
    "folder_path = \"updated_data_sliding\"\n",
    "\n",
    "# Define the path to the norm_dated_data folder\n",
    "output_folder = \"updated_data_sliding_norm\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Iterate through each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        output_file_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Exclude the DateTime column from normalization\n",
    "        columns_to_normalize = df.columns[df.columns != \"DateTime\"]\n",
    "        \n",
    "        # Create a MinMaxScaler and fit-transform the data\n",
    "        scaler = MinMaxScaler()\n",
    "        df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
    "        \n",
    "        # Save the normalized data to the output folder\n",
    "        df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating seperate file for each date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path of the folder containing the CSV files\n",
    "folder_path = 'updated_data_sliding_norm'\n",
    "\n",
    "# Create a new folder to store the dated data files\n",
    "output_folder = 'updated_data_sliding_norm_dated'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate over the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Extract the subject ID from the filename\n",
    "        subject_id = filename.split('_')[0]+'_'+filename.split('_')[1][:-4]\n",
    "        # print(subject_id)\n",
    "        # Read the CSV file\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        #  # Rename the first column as \"DateTime\"\n",
    "        # df = df.rename(columns={df.columns[0]: \"DateTime\"})\n",
    "        \n",
    "        # Extract the first 6 characters from the DateTime column\n",
    "        df['DatePrefix'] = df['DateTime'].str[:8]\n",
    "        \n",
    "        \n",
    "        # Group the data by the DatePrefix and iterate over each group\n",
    "        grouped = df.groupby('DatePrefix')\n",
    "        for date_prefix, group in grouped:\n",
    "            # Create a new filename for the date\n",
    "            new_filename = f\"{subject_id}_{date_prefix}.csv\"\n",
    "            \n",
    "            # Save the group data to a new CSV file\n",
    "            output_path = os.path.join(output_folder, new_filename)\n",
    "            group.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path of the folder containing the CSV files\n",
    "folder_path = 'updated_data_sliding_norm_dated'\n",
    "\n",
    "# Iterate over the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read the CSV file\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Remove the 'DatePrefix' column\n",
    "        if 'DatePrefix' in df.columns:\n",
    "            df = df.drop('DatePrefix', axis=1)\n",
    "        \n",
    "        # Save the modified DataFrame back to the CSV file\n",
    "        df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv('fatiguelevel.csv')\n",
    "\n",
    "# Convert Subject_ID to integer\n",
    "df['Subject_ID'] = df['Subject_ID'].astype(int)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv('fatiguelevel.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a csv file which contains file address and label for that day strressed or not stressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the fatiguelevel.csv file\n",
    "df = pd.read_csv('fatiguelevel.csv')\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "file_locs = []\n",
    "for index, row in df.iterrows():\n",
    "    subject_id = row['Subject_ID']\n",
    "    date = row['DateTime'][:8]  # Get the first 8 letters of the DateTime\n",
    "    \n",
    "    # Generate the file path\n",
    "    file_name = f\"subjectID_{subject_id}_{date}.csv\"\n",
    "    file_path = os.path.join('updated_data_sliding_norm_dated', file_name)\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        file_locs.append(file_path)\n",
    "    else:\n",
    "        file_locs.append('')  # Empty string if file doesn't exist\n",
    "\n",
    "# Add the file_loc column to the DataFrame\n",
    "df['file_loc'] = file_locs\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv('fatiguelevel_updated.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the updated CSV file\n",
    "df = pd.read_csv('fatiguelevel_updated.csv')\n",
    "\n",
    "# Move the 'file_loc' column to the beginning of the DataFrame\n",
    "cols = df.columns.tolist()\n",
    "cols = ['file_loc'] + cols[:-1]\n",
    "df = df[cols]\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv('fatiguelevel_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with null 'file_loc': 67\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows with null values in the 'file_loc' column\n",
    "null_count = df['file_loc'].isnull().sum()\n",
    "\n",
    "# Display the number of rows with null values in the 'file_loc' column\n",
    "print(\"Number of rows with null 'file_loc':\", null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with null values in the 'file_loc' column\n",
    "df = df.dropna(subset=['file_loc'])\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv('fatiguelevel_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_loc</th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Average_Stress</th>\n",
       "      <th>Stressed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>updated_data_sliding_norm_dated\\subjectID_1_14...</td>\n",
       "      <td>1</td>\n",
       "      <td>14.03.19 20:01</td>\n",
       "      <td>0.214444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>updated_data_sliding_norm_dated\\subjectID_1_15...</td>\n",
       "      <td>1</td>\n",
       "      <td>15.03.19 20:01</td>\n",
       "      <td>0.224444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>updated_data_sliding_norm_dated\\subjectID_1_16...</td>\n",
       "      <td>1</td>\n",
       "      <td>16.03.19 20:47</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>updated_data_sliding_norm_dated\\subjectID_1_17...</td>\n",
       "      <td>1</td>\n",
       "      <td>17.03.19 20:01</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>updated_data_sliding_norm_dated\\subjectID_1_18...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.03.19 20:13</td>\n",
       "      <td>0.294444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>updated_data_sliding_norm_dated\\subjectID_28_1...</td>\n",
       "      <td>28</td>\n",
       "      <td>10.08.18 23:13</td>\n",
       "      <td>0.264462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>updated_data_sliding_norm_dated\\subjectID_28_1...</td>\n",
       "      <td>28</td>\n",
       "      <td>13.08.18 21:39</td>\n",
       "      <td>0.427505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>updated_data_sliding_norm_dated\\subjectID_28_1...</td>\n",
       "      <td>28</td>\n",
       "      <td>14.08.18 23:27</td>\n",
       "      <td>0.426277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>updated_data_sliding_norm_dated\\subjectID_28_1...</td>\n",
       "      <td>28</td>\n",
       "      <td>16.08.18 00:51</td>\n",
       "      <td>0.301895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>updated_data_sliding_norm_dated\\subjectID_28_1...</td>\n",
       "      <td>28</td>\n",
       "      <td>16.08.18 00:52</td>\n",
       "      <td>0.199247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>459 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_loc  Subject_ID  \\\n",
       "0    updated_data_sliding_norm_dated\\subjectID_1_14...           1   \n",
       "1    updated_data_sliding_norm_dated\\subjectID_1_15...           1   \n",
       "2    updated_data_sliding_norm_dated\\subjectID_1_16...           1   \n",
       "3    updated_data_sliding_norm_dated\\subjectID_1_17...           1   \n",
       "4    updated_data_sliding_norm_dated\\subjectID_1_18...           1   \n",
       "..                                                 ...         ...   \n",
       "521  updated_data_sliding_norm_dated\\subjectID_28_1...          28   \n",
       "522  updated_data_sliding_norm_dated\\subjectID_28_1...          28   \n",
       "523  updated_data_sliding_norm_dated\\subjectID_28_1...          28   \n",
       "524  updated_data_sliding_norm_dated\\subjectID_28_1...          28   \n",
       "525  updated_data_sliding_norm_dated\\subjectID_28_1...          28   \n",
       "\n",
       "           DateTime  Average_Stress  Stressed  \n",
       "0    14.03.19 20:01        0.214444         0  \n",
       "1    15.03.19 20:01        0.224444         0  \n",
       "2    16.03.19 20:47        0.060000         0  \n",
       "3    17.03.19 20:01        0.190000         0  \n",
       "4    18.03.19 20:13        0.294444         0  \n",
       "..              ...             ...       ...  \n",
       "521  10.08.18 23:13        0.264462         0  \n",
       "522  13.08.18 21:39        0.427505         0  \n",
       "523  14.08.18 23:27        0.426277         0  \n",
       "524  16.08.18 00:51        0.301895         0  \n",
       "525  16.08.18 00:52        0.199247         0  \n",
       "\n",
       "[459 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with 'stressed' column value as 0: 422\n",
      "Number of rows with 'stressed' column value as 1: 104\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('fatiguelevel.csv')\n",
    "# Count the number of rows with 'stressed' column value as 0 and 1\n",
    "count_0 = data[data['Stressed'] == 0].shape[0]\n",
    "count_1 = data[data['Stressed'] == 1].shape[0]\n",
    "\n",
    "print(\"Number of rows with 'stressed' column value as 0:\", count_0)\n",
    "print(\"Number of rows with 'stressed' column value as 1:\", count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with 'stressed' column value as 0: 369\n",
      "Number of rows with 'stressed' column value as 1: 90\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows with 'stressed' column value as 0 and 1\n",
    "count_0 = df[df['Stressed'] == 0].shape[0]\n",
    "count_1 = df[df['Stressed'] == 1].shape[0]\n",
    "\n",
    "print(\"Number of rows with 'stressed' column value as 0:\", count_0)\n",
    "print(\"Number of rows with 'stressed' column value as 1:\", count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
