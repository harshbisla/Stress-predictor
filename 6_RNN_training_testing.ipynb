{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 'fatiguelevel_updated.csv' file\n",
    "data_df = pd.read_csv('fatiguelevel_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the file paths and labels\n",
    "\n",
    "file_paths = data_df['file_loc'].values\n",
    "labels = data_df['Stressed'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "data = []\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path)\n",
    "    data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to numpy array\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features shape: (459, 720, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the shapes of the input features and labels\n",
    "print(\"Input features shape:\", data.shape)\n",
    "# print(\"Labels shape:\", np.array(labels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "# The validation size can be set to a specific percentage of the training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the shape of the input data\n",
    "num_samples = data.shape[0]\n",
    "num_timesteps = data.shape[1]  # Number of time steps\n",
    "num_features = data.shape[2]  # Number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to create the model\n",
    "def create_model(units=64, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, input_shape=(data.shape[1], data.shape[2])))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harsh Bisla\\AppData\\Local\\Temp\\ipykernel_5800\\1610858891.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model)\n"
     ]
    }
   ],
   "source": [
    "# Create the KerasClassifier wrapper\n",
    "model = KerasClassifier(build_fn=create_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 4s 458ms/step - loss: 0.7259 - accuracy: 0.1639\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6977 - accuracy: 0.4516\n",
      "2/2 [==============================] - 4s 454ms/step - loss: 0.7023 - accuracy: 0.3607\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.6686 - accuracy: 0.6774\n",
      "2/2 [==============================] - 4s 347ms/step - loss: 0.7365 - accuracy: 0.2258\n",
      "1/1 [==============================] - 1s 943ms/step - loss: 0.7243 - accuracy: 0.1667\n",
      "2/2 [==============================] - 4s 492ms/step - loss: 0.7083 - accuracy: 0.3115\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 0.6691 - accuracy: 0.7742\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x000001BAE49BF380> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 4s 546ms/step - loss: 0.6511 - accuracy: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BAE4C77A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6321 - accuracy: 0.7742\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x000001BADAC618A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 4s 499ms/step - loss: 0.6376 - accuracy: 0.7742\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x000001BADAE0CFE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 0.5392 - accuracy: 0.9333\n",
      "2/2 [==============================] - 7s 1s/step - loss: 0.6856 - accuracy: 0.5410\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6271 - accuracy: 0.7742\n",
      "2/2 [==============================] - 5s 1s/step - loss: 0.7310 - accuracy: 0.2295\n",
      "1/1 [==============================] - 1s 915ms/step - loss: 0.6567 - accuracy: 0.7742\n",
      "2/2 [==============================] - 5s 984ms/step - loss: 0.6675 - accuracy: 0.7258\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5391 - accuracy: 0.9333\n",
      "3/3 [==============================] - 7s 676ms/step - loss: 0.6517 - accuracy: 0.7391\n",
      "Best Parameters:  {'units': 64}\n",
      "Best Accuracy:  0.8272401293118795\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'units': [32, 64, 128],  # Number of LSTM units\n",
    "}\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid_search.fit(X_test, y_test)\n",
    "\n",
    "# Print the best parameters and accuracy\n",
    "print(\"Best Parameters: \", grid_result.best_params_)\n",
    "print(\"Best Accuracy: \", grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=32, input_shape=(data.shape[1], data.shape[2])))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.callbacks import ModelCheckpoint\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 9s 622ms/step - loss: 0.5643 - accuracy: 0.8089 - val_loss: 0.4694 - val_accuracy: 0.8243\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 5s 548ms/step - loss: 0.4848 - accuracy: 0.8123 - val_loss: 0.4714 - val_accuracy: 0.8243\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 5s 461ms/step - loss: 0.4984 - accuracy: 0.8123 - val_loss: 0.4818 - val_accuracy: 0.8243\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 5s 511ms/step - loss: 0.4833 - accuracy: 0.8123 - val_loss: 0.4658 - val_accuracy: 0.8243\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 6s 572ms/step - loss: 0.4828 - accuracy: 0.8123 - val_loss: 0.4651 - val_accuracy: 0.8243\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 5s 547ms/step - loss: 0.4749 - accuracy: 0.8123 - val_loss: 0.4669 - val_accuracy: 0.8243\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 5s 472ms/step - loss: 0.4782 - accuracy: 0.8123 - val_loss: 0.4666 - val_accuracy: 0.8243\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 5s 501ms/step - loss: 0.4784 - accuracy: 0.8123 - val_loss: 0.4698 - val_accuracy: 0.8243\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 5s 548ms/step - loss: 0.4742 - accuracy: 0.8123 - val_loss: 0.4618 - val_accuracy: 0.8243\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 5s 516ms/step - loss: 0.4663 - accuracy: 0.8123 - val_loss: 0.4629 - val_accuracy: 0.8243\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 5s 553ms/step - loss: 0.4686 - accuracy: 0.8123 - val_loss: 0.4641 - val_accuracy: 0.8243\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 5s 462ms/step - loss: 0.4846 - accuracy: 0.8123 - val_loss: 0.4717 - val_accuracy: 0.8243\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 5s 498ms/step - loss: 0.4734 - accuracy: 0.8123 - val_loss: 0.4633 - val_accuracy: 0.8243\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 5s 472ms/step - loss: 0.4703 - accuracy: 0.8123 - val_loss: 0.4665 - val_accuracy: 0.8243\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 5s 472ms/step - loss: 0.4743 - accuracy: 0.8123 - val_loss: 0.4642 - val_accuracy: 0.8243\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 5s 487ms/step - loss: 0.4686 - accuracy: 0.8123 - val_loss: 0.4611 - val_accuracy: 0.8243\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 5s 468ms/step - loss: 0.4691 - accuracy: 0.8123 - val_loss: 0.4621 - val_accuracy: 0.8243\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 6s 574ms/step - loss: 0.4652 - accuracy: 0.8123 - val_loss: 0.4644 - val_accuracy: 0.8243\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 6s 622ms/step - loss: 0.4670 - accuracy: 0.8123 - val_loss: 0.4649 - val_accuracy: 0.8243\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 5s 550ms/step - loss: 0.4634 - accuracy: 0.8157 - val_loss: 0.4641 - val_accuracy: 0.8243\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 7s 671ms/step - loss: 0.4619 - accuracy: 0.8157 - val_loss: 0.4641 - val_accuracy: 0.8243\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 7s 682ms/step - loss: 0.4546 - accuracy: 0.8123 - val_loss: 0.4671 - val_accuracy: 0.8243\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 9s 876ms/step - loss: 0.4525 - accuracy: 0.8157 - val_loss: 0.4700 - val_accuracy: 0.8108\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 8s 746ms/step - loss: 0.4560 - accuracy: 0.8123 - val_loss: 0.4719 - val_accuracy: 0.8243\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 7s 647ms/step - loss: 0.4603 - accuracy: 0.8157 - val_loss: 0.4689 - val_accuracy: 0.8243\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 7s 672ms/step - loss: 0.4637 - accuracy: 0.8157 - val_loss: 0.4700 - val_accuracy: 0.8243\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 7s 736ms/step - loss: 0.4606 - accuracy: 0.8157 - val_loss: 0.4644 - val_accuracy: 0.8243\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 6s 566ms/step - loss: 0.4608 - accuracy: 0.8123 - val_loss: 0.4628 - val_accuracy: 0.8243\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 6s 629ms/step - loss: 0.4574 - accuracy: 0.8157 - val_loss: 0.4682 - val_accuracy: 0.8243\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 7s 736ms/step - loss: 0.4557 - accuracy: 0.8157 - val_loss: 0.4659 - val_accuracy: 0.8243\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 8s 784ms/step - loss: 0.4550 - accuracy: 0.8123 - val_loss: 0.4670 - val_accuracy: 0.8243\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 7s 691ms/step - loss: 0.4592 - accuracy: 0.8157 - val_loss: 0.4730 - val_accuracy: 0.8243\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 6s 588ms/step - loss: 0.4537 - accuracy: 0.8191 - val_loss: 0.5040 - val_accuracy: 0.7973\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 6s 619ms/step - loss: 0.4646 - accuracy: 0.8157 - val_loss: 0.4748 - val_accuracy: 0.8243\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 5s 489ms/step - loss: 0.4604 - accuracy: 0.8123 - val_loss: 0.4760 - val_accuracy: 0.8243\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 5s 512ms/step - loss: 0.4892 - accuracy: 0.8123 - val_loss: 0.5081 - val_accuracy: 0.8243\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 6s 606ms/step - loss: 0.4680 - accuracy: 0.8157 - val_loss: 0.4738 - val_accuracy: 0.8243\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 7s 654ms/step - loss: 0.4589 - accuracy: 0.8123 - val_loss: 0.4739 - val_accuracy: 0.8243\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 7s 693ms/step - loss: 0.4468 - accuracy: 0.8157 - val_loss: 0.4701 - val_accuracy: 0.8108\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 6s 574ms/step - loss: 0.4491 - accuracy: 0.8123 - val_loss: 0.5170 - val_accuracy: 0.7838\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 6s 635ms/step - loss: 0.4633 - accuracy: 0.8157 - val_loss: 0.4900 - val_accuracy: 0.8243\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 6s 643ms/step - loss: 0.4740 - accuracy: 0.8123 - val_loss: 0.4799 - val_accuracy: 0.8243\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 6s 603ms/step - loss: 0.4716 - accuracy: 0.8123 - val_loss: 0.4741 - val_accuracy: 0.8243\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 6s 584ms/step - loss: 0.4677 - accuracy: 0.8123 - val_loss: 0.4760 - val_accuracy: 0.8243\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 7s 752ms/step - loss: 0.4674 - accuracy: 0.8123 - val_loss: 0.4739 - val_accuracy: 0.8243\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 8s 836ms/step - loss: 0.4589 - accuracy: 0.8123 - val_loss: 0.4728 - val_accuracy: 0.8243\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 7s 672ms/step - loss: 0.4683 - accuracy: 0.8157 - val_loss: 0.4789 - val_accuracy: 0.8243\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 7s 689ms/step - loss: 0.4589 - accuracy: 0.8123 - val_loss: 0.4741 - val_accuracy: 0.8243\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 6s 631ms/step - loss: 0.4665 - accuracy: 0.8123 - val_loss: 0.4726 - val_accuracy: 0.8243\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 5s 547ms/step - loss: 0.4562 - accuracy: 0.8157 - val_loss: 0.4733 - val_accuracy: 0.8243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1514b518f50>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# if not os.path.exists('models'):\n",
    "#     os.makedirs('models')\n",
    "# # Define a checkpoint callback to save the best model based on validation accuracy\n",
    "# checkpoint = ModelCheckpoint('models/mymodel.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 167ms/step - loss: 0.5840 - accuracy: 0.7609\n",
      "Test Loss: 0.584013\n",
      "Test Accuracy: 0.760870\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001514C008540> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 1s 149ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:f}')\n",
    "print(f'Test Accuracy: {accuracy:f}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 66ms/step - loss: 0.8620 - accuracy: 0.6739\n",
      "Test accuracy of the best model: 0.6739\n"
     ]
    }
   ],
   "source": [
    "# # Load the best model from the saved checkpoint\n",
    "# best_model = keras.models.load_model('models/mymodel.h5')\n",
    "\n",
    "# # Assuming you have your test data (X_test and y_test) ready\n",
    "# # If you don't have the test data, prepare it using your dataset\n",
    "\n",
    "# # Evaluate the best model on the test data\n",
    "# loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "\n",
    "# # Print the accuracy\n",
    "# print(f'Test accuracy of the best model: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
